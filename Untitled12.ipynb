{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3EmLyUsmt74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9kScuBDmxE-",
        "outputId": "b7208639-cb90-4cfe-93df-ac097b8aa637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL_ziAmht6FG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the Hugging Face API token\n",
        "os.environ['HUGGINGFACE_API_TOKEN'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLJ2PHT5t6B8"
      },
      "outputs": [],
      "source": [
        "#we have to take the input from thr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUlOL64pt5vs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvZca3Fjmxuo",
        "outputId": "8df95355-6efd-4eef-a2bb-d51c8fc989c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers huggingface_hub textblob matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF8PEW2hnGWk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from transformers import pipeline\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeqU5DBznJl4"
      },
      "outputs": [],
      "source": [
        "def authenticate_huggingface():\n",
        "    api_token = os.getenv('HUGGINGFACE_API_TOKEN')\n",
        "    if not api_token:\n",
        "        print(\"Error: Hugging Face API token not found. Please set the 'HUGGINGFACE_API_TOKEN' environment variable.\")\n",
        "        sys.exit(1)\n",
        "    # Authentication is handled internally by the transformers library when using the pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "701wExWsnJil"
      },
      "outputs": [],
      "source": [
        "def initialize_model():\n",
        "    try:\n",
        "        generator = pipeline('text-generation', model='gpt2', use_auth_token=True)\n",
        "        return generator\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing the model: {e}\")\n",
        "        sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wJ0HaOfnJfd"
      },
      "outputs": [],
      "source": [
        "def get_gpt_response(generator, user_input, max_length=100):\n",
        "    try:\n",
        "        response = generator(user_input, max_length=max_length, num_return_sequences=1)\n",
        "        generated_text = response[0]['generated_text'].strip()\n",
        "        return generated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return \"I'm sorry, I couldn't process that.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD63uHysnJby"
      },
      "outputs": [],
      "source": [
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Negative'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZeGTOU_nJYF"
      },
      "outputs": [],
      "source": [
        "def generate_visualization(sentiment_results):\n",
        "    sentiment_counts = {\n",
        "        'Positive': sentiment_results.count('Positive'),\n",
        "        'Negative': sentiment_results.count('Negative'),\n",
        "        'Neutral': sentiment_results.count('Neutral')\n",
        "    }\n",
        "\n",
        "    labels = sentiment_counts.keys()\n",
        "    sizes = sentiment_counts.values()\n",
        "    colors = ['#66b3ff','#ff9999','#99ff99']\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140, shadow=True)\n",
        "    plt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
        "    plt.title('Sentiment Analysis Distribution')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A42hbIfSnJUu"
      },
      "outputs": [],
      "source": [
        "def generate_bar_chart(sentiment_results):\n",
        "    sentiment_counts = {\n",
        "        'Positive': sentiment_results.count('Positive'),\n",
        "        'Negative': sentiment_results.count('Negative'),\n",
        "        'Neutral': sentiment_results.count('Neutral')\n",
        "    }\n",
        "\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.barplot(x=list(sentiment_counts.keys()), y=list(sentiment_counts.values()), palette='viridis')\n",
        "    plt.title('Sentiment Analysis Distribution')\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUg02jlwnJRh"
      },
      "outputs": [],
      "source": [
        "def run_chat():\n",
        "    authenticate_huggingface()\n",
        "    generator = initialize_model()\n",
        "    sentiment_results = []\n",
        "    conversation_log = []\n",
        "\n",
        "    print(\"Welcome to the GPT-3 Chatbot! Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Ending conversation. Generating report...\\n\")\n",
        "            break\n",
        "\n",
        "        # Generate GPT response\n",
        "        gpt_response = get_gpt_response(generator, user_input)\n",
        "        print(f\"AI: {gpt_response}\\n\")\n",
        "\n",
        "        # Analyze sentiment\n",
        "        sentiment = analyze_sentiment(gpt_response)\n",
        "        print(f\"Sentiment: {sentiment}\\n\")\n",
        "\n",
        "        # Store results\n",
        "        sentiment_results.append(sentiment)\n",
        "        conversation_log.append({\n",
        "            'user_input': user_input,\n",
        "            'gpt_response': gpt_response,\n",
        "            'sentiment': sentiment\n",
        "        })\n",
        "\n",
        "    # Generate Visualization\n",
        "    generate_visualization(sentiment_results)\n",
        "\n",
        "    # Optionally, save the conversation log\n",
        "    save_conversation_log(conversation_log)\n",
        "\n",
        "    print(\"Report generated successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI9OnfkNnJOO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def save_conversation_log(conversation_log, filename='conversation_log.json'):\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(conversation_log, f, indent=4)\n",
        "        print(f\"Conversation log saved to {filename}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving conversation log: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTv1qdimnJKj",
        "outputId": "75b61f64-69cc-4439-8234-d27213c138ee"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the GPT-3 Chatbot! Type 'exit' to end the conversation.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating response: The following `model_kwargs` are not used by the model: ['use_auth_token'] (note: typos in the generate arguments will also show up in this list)\n",
            "AI: I'm sorry, I couldn't process that.\n",
            "\n",
            "Sentiment: Negative\n",
            "\n",
            "Error generating response: The following `model_kwargs` are not used by the model: ['use_auth_token'] (note: typos in the generate arguments will also show up in this list)\n",
            "AI: I'm sorry, I couldn't process that.\n",
            "\n",
            "Sentiment: Negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_chat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tp9EwHLtDaX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHutWn4AtDWu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIgthk5mtDT7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtQdLmT4tDRR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6-dSkBytDON"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0r_bP-5tDLO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S_m3y0ItDIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFYTaLx0BAGe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}